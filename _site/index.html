<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Vanya Cohen</title>
  <meta name="description" content="PhD Student in Computer Science at UT Austin.">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
  <link rel="canonical" href="http://localhost:4000/">
  <!--  -->
  
  <link rel="alternate" type="application/rss+xml" title="Vanya Cohen" href="http://localhost:4000/feed.xml">

  <link rel="manifest" href="/site.webmanifest">

<script src="/assets/js/main.min.js"></script>
<script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js" integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous"></script>

  
  <meta property="og:title" content="Vanya Cohen">
  <meta property="og:site_name" content="Vanya Cohen">
  <meta property="og:url" content="http://localhost:4000/">
  <meta property="og:description" content="PhD Student in Computer Science at UT Austin.">
  
  
    <meta property="og:image" content="">
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="vanyacohen">
  <meta name="twitter:title" content="Vanya Cohen">
  <meta name="twitter:description" content="PhD Student in Computer Science at UT Austin.">
  
    <meta name="twitter:creator" content="vanyacohen">
  
  
    <meta name="twitter:image:src" content="">
  

  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Bitter:400,400i,700&amp;display=swap" rel="stylesheet">

  
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'G-LCHLKKCF7R', 'auto');
    ga('send', 'pageview');

  </script>


</head>


  <body>
    <div class="home">
      <div id="main" role="main">
        <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Vanya Cohen</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/#about">About</a>
      
        
        <a class="page-link" href="/#news">News</a>
      
        
        <a class="page-link" href="/#publications">Publications</a>
      
        
        <a class="page-link" href="https://substack.com/@vanyacohen">Blog</a>
      
        
        <a class="page-link" href="/assets/cv/CV.pdf">CV</a>
      
    </nav>

  </div>

</header>


        <main class="page-content" aria-label="Content">
          <div class="wrapper">
            <div class="home">

  <table>
    <colgroup>
        <col width="12%" />
        <col width="5%" />
        <col width="70%" />
    </colgroup>
    <tbody>
        <tr style="vertical-align: top;">
            <td>
                <img src="/assets/img/profile.jpg" align="left" alt="Vanya Cohen" style="margin: 0px 10px 0px 0px;" />
                <br clear="all" /><br clear="all" />
                <div class="meta-center">
                <nobr><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> <a href="https://mailhide.io/e/OW8hdvV3">Email</a></nobr>
                <br />
                <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Boston, MA</span>
                <br clear="all" /><br clear="all" />
                <div style="font-size: 24px">
                <a href="https://twitter.com/vanyacohen" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i></a>
                <span>&#183;</span>
                <a href="https://scholar.google.com/citations?user=VSc-eTAAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-graduation-cap" aria-hidden="true"></i></a>
                <span>&#183;</span>
                <a href="https://www.linkedin.com/in/vanyacohen" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i></a>
                </div>
                </div>
            </td>
            <td></td>
            <td>  
                I am a PhD Student at the 
                <a href="https://www.cs.utexas.edu/~ml/">University of Texas at Austin</a> (currently on leave)
                 and Research Scientist at <a href="https://blackbird.ai">Blackbird.AI</a>, where I created <a href="https://blackbird.ai/compass-context/">Compass</a>, an agentic fact-checker for multimodal social media content. My PhD advisor is <a href="https://www.cs.utexas.edu/~mooney/">Ray Mooney</a>.
                <ul></ul>
                <b>Research:</b> My research centers on grounded natural language processing, reinforcement learning, and robotics. Broadly, I am interested in creating AI systems that can understand and interact with complex environments through language and action.
                <ul></ul>
                <b>Timeline:</b> Before starting my PhD and position at <a href="https://blackbird.ai">Blackbird.AI</a>, I worked at <a href="https://en.wikipedia.org/wiki/Luminoso">Luminoso</a> in Boston, contributing to <a href="https://conceptnet.io">ConceptNet</a>.<br />
                I completed my B.Sc. and M.Sc. in Computer Science at 
                <a href="https://cs.brown.edu">Brown University</a>, where I was advised by Stefanie Tellex and George Konidaris in the 
                <a href="https://h2r.cs.brown.edu">Humans to Robots Lab</a>.
                <ul></ul>
                <b>Fun facts:</b> I helped create the first publicly released, open-source LLM <a href="https://www.wired.com/story/dangerous-ai-open-source/">OpenGPT-2</a> and dataset <a href="https://huggingface.co/datasets/Skylion007/openwebtext">OpenWebText</a>. My <a href="https://www.csauthors.net/distance/vanya-cohen/paul-erdos">Erdős number is 3</a>.
            </td>
        </tr>
    </tbody>
</table>

<hr />

<h2 id="news">News</h2>

<ul>
  <li>
    <p><strong>[November 2024]</strong>: Excited to share <strong>CaT-Bench</strong>! Our benchmark, <a href="http://www.arxiv.org/abs/2406.15823"><strong>CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans</strong></a>, presented at <a href="https://2024.emnlp.org/">EMNLP 2024</a>, evaluates how language models handle step dependencies in procedure understanding, revealing challenges for state-of-the-art models. <a href="https://huggingface.co/datasets/vanyacohen/CaT-Bench">Check out CaT-Bench on HuggingFace</a> and explore the <a href="https://github.com/StonyBrookNLP/CaT-Bench">code here</a>.</p>
  </li>
  <li>
    <p><strong>[August 2024]</strong>: We’ve presented <a href="http://www.arxiv.org/abs/2405.13245"><strong>A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings</strong></a> in the <a href="https://ijcai24.org/call-for-papers-survey-track/">IJCAI 2024: Survey Track</a>! This paper explores the trade-offs in robotic language grounding between symbolic and vector-space representations, with insights into interpretability, generalizability, and scalability. Read more on the <a href="https://h2r.cs.brown.edu/a-survey-of-robotic-language-grounding-tradeoffs-between-symbols-and-embeddings/">blog</a>.</p>
  </li>
  <li>
    <p><strong>[May 2024]</strong>: Announcing <strong>CAPE</strong>! In our <a href="https://2024.ieee-icra.org/">ICRA 2024</a> paper, <a href="http://www.arxiv.org/abs/2211.09935"><strong>CAPE: Corrective Actions from Precondition Errors using Large Language Models</strong></a>, we introduced a method that empowers robots to autonomously make corrective actions by re-prompting large language models. Our implementation on the Spot robot demonstrates significant advancements in LLM-assisted robotic planning. Discover more on the <a href="https://shreyas-s-raman.github.io/CAPE/">CAPE project page</a> and check out our <a href="https://shreyas-s-raman.github.io/CAPE/">code base</a>.</p>
  </li>
</ul>

<hr />

<!-- Add this style block at the beginning of your file -->
<style>
  @media screen and (max-width: 600px) {
    .paper-image {
      display: none;
    }
    .paper-container {
      flex-direction: column;
      align-items: flex-start;
    }
  }
</style>

<!-- Your content starts here -->
<h2 id="publications">Publications</h2>

<h3 id="2024">2024</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/catbench.png" alt="CaT-Bench" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="http://www.arxiv.org/abs/2406.15823" style="font-weight: bold;">CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans</a><br />
    Yash Kumar Lal*, <strong>Vanya Cohen*</strong>, Nathanael Chambers, Niranjan Balasubramanian, Raymond Mooney.<br />
    <em>EMNLP 2024</em>, June 2024.<br />
    <a href="http://www.arxiv.org/abs/2406.15823">[paper]</a>
    <a href="https://huggingface.co/datasets/vanyacohen/CaT-Bench">[dataset]</a>
    <a href="https://github.com/StonyBrookNLP/CaT-Bench">[code]</a><br />
    A benchmark that evaluates language models' ability to reason about step dependencies in task plans, using causal and temporal relations. We find SOTA LLMs perform poorly on this task despite its simplicity.
  </div>
</div>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/lang-survey.png" alt="Language Grounding Survey" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="http://www.arxiv.org/abs/2405.13245" style="font-weight: bold;">A Survey of Robotic Language Grounding: Tradeoffs Between Symbols and Embeddings</a><br />
    <strong>Vanya Cohen*</strong>, Jason Xinyu Liu*, Raymond Mooney*, Stefanie Tellex*, David Watkins*.<br />
    <em>IJCAI Survey Track</em>, May 2024.<br />
    <a href="http://www.arxiv.org/abs/2405.13245">[paper]</a>
    <a href="https://h2r.cs.brown.edu/a-survey-of-robotic-language-grounding-tradeoffs-between-symbols-and-embeddings/">[project page]</a><br />
    Robotic language grounding methods can be positioned along an axis that ranges from methods that map natural language to formal symbolic representations to those that map to high-dimensional vector spaces. The survey explores the trade-offs between interpretability, generalizability, and scalability.
  </div>
</div>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/cape.png" alt="CAPE" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="http://www.arxiv.org/abs/2211.09935" style="font-weight: bold;">CAPE: Corrective Actions from Precondition Errors using Large Language Models</a><br />
    Shreyas Sundara Raman, <strong>Vanya Cohen</strong>, Ifrah Idrees, Eric Rosen, Ray Mooney, Stefanie Tellex, David Paulius.<br />
    <em>ICRA 2024</em>, May 2024.<br />
    <a href="http://www.arxiv.org/abs/2211.09935">[paper]</a>
    <a href="https://shreyas-s-raman.github.io/CAPE/">[code]</a>
    <a href="https://shreyas-s-raman.github.io/CAPE/">[project page]</a><br />
    CAPE resolves precondition errors in task planning for robotic agents by leveraging large language models. The method re-prompts LLMs using error feedback, allowing robots to make corrective actions in real-world environments.
  </div>
</div>

<h3 id="2023">2023</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/planning_semantic_parsing.png" alt="Using Planning to Improve Semantic Parsing of Instructional Texts" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://aclanthology.org/2023.nlrse-1.5.pdf" style="font-weight: bold;">Using Planning to Improve Semantic Parsing of Instructional Texts</a><br />
    <strong>Vanya Cohen</strong>, Raymond Mooney<br />
    <em>Workshop on Natural Language Reasoning and Structured Explanations at ACL 2023</em>, June 2023, Pages 47-58.<br />
    <a href="https://aclanthology.org/2023.nlrse-1.5.pdf">[paper]</a><br />
    A symbolic planning-based decoder is introduced to enhance semantic parsing in instructional texts. Leveraging large language models, it generates action sequences in a formal language for improved execution accuracy in few-shot settings. Evaluation demonstrates significant gains in parsing quality across two recipe instruction domains.
  </div>
</div>

<h3 id="2022">2022</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/compositional_policies_corl2022.png" alt="End-to-End Learning to Follow Language Instructions with Compositional Policies" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://openreview.net/pdf?id=ZysLprv3e69" style="font-weight: bold;">End-to-End Learning to Follow Language Instructions with Compositional Policies</a><br />
    <strong>Vanya Cohen*</strong>, Geraud Nangue Tasse*, Nakul Gopalan, Steven James, Ray Mooney, Benjamin Rosman<br />
    <em>Workshop on Language and Robotics at CoRL 2022</em>, December 2022.<br />
    <a href="https://openreview.net/pdf?id=ZysLprv3e69">[paper]</a><br />
    This paper introduces an end-to-end model combining large language models with pretrained compositional value functions to execute goal-reaching tasks specified in natural language. Evaluations in the BabyAI environment demonstrate the model's ability to generalize zero-shot to new combinations of task attributes.
  </div>
</div>

<h3 id="2021">2021</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/compositional_policies_aaai_fss_2.png" alt="Learning to Follow Language Instructions with Compositional Policies" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://arxiv.org/pdf/2110.04647" style="font-weight: bold;">Learning to Follow Language Instructions with Compositional Policies</a><br />
    <strong>Vanya Cohen*</strong>, Geraud Nangue Tasse*, Nakul Gopalan, Steven James, Matthew Gombolay, Benjamin Rosman<br />
    <em>AI-HRI Symposium at AAAI-FSS 2021</em>, October 2021.<br />
    <a href="https://arxiv.org/pdf/2110.04647">[paper]</a><br />
    A new framework leverages compositionality in value functions and language to execute natural language instructions in goal-reaching tasks. Using Boolean algebra to compose value functions, the approach reduces training steps by 86% for new tasks in the BabyAI domain, demonstrating efficient generalization.
  </div>
</div>

<h3 id="2020">2020</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/newinml_neurips2020.png" alt="NewInML @ NeurIPS 2020" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://nips.cc/virtual/2020/public/affinity_workshop_19448.html" style="font-weight: bold;">Co-Organizer: NewInML @ NeurIPS 2020: A Workshop for Newcomers to Machine Learning</a><br />
    Zhen Xu, <strong>Vanya Cohen</strong>, Shruti Mishra, MingYu Lu<br />
    <em>NewInML @ NeurIPS 2020</em>, December 2020.<br />
    <a href="https://nips.cc/virtual/2020/public/affinity_workshop_19448.html">[workshop]</a><br />
    Sessions included talks by renowned speakers such as Dr. Samy Bengio, Prof. David Jensen, Prof. Anima Anandkumar, and Prof. Isabelle Guyon, as well as a panel discussion with prominent ML experts. The workshop aimed to guide new researchers through the process of publishing high-quality papers, with oral presentations and awards for standout contributions.
  </div>
</div>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/opengpt2_xrds.png" alt="OpenGPT-2" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://dl.acm.org/doi/abs/10.1145/3416063" style="font-weight: bold;">OpenGPT-2: Open Language Models and Implications of Generated Text</a><br />
    <strong>Vanya Cohen</strong>, Aaron Gokaslan<br />
    <em>XRDS: Crossroads, The ACM Magazine for Students Fall 2020</em>, September 2020.<br />
    <a href="https://dl.acm.org/doi/abs/10.1145/3416063">[article]</a><br />
    Guest feature in ACM's XRDS Magazine. When OpenAI released its billion-parameter language model GPT-2, their attempts to withhold the model inspired two researchers to use open research practices to combat the misuse of machine learning.
  </div>
</div>

<h3 id="2019">2019</h3>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/opengpt2.png" alt="OpenGPT-2" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc" style="font-weight: bold;">OpenGPT-2: We Replicated GPT-2 Because You Can Too</a><br />
    Aaron Gokaslan*, <strong>Vanya Cohen*</strong>, Ellie Pavlick, Stefanie Tellex.<br />
    <em>NeurIPS NewInML Workshop</em>, December 2019.<br />
    <a href="https://www.wired.com/story/dangerous-ai-open-source/">[article]</a>
    <a href="https://github.com/Skylion007/openwebtext">[code]</a><br />
    OpenGPT-2 is a replication of OpenAI's GPT-2 model, featuring one of the first publicly accessible language models. It utilized the OpenWebText dataset and helped pave the way for open-source LLMs.
  </div>
</div>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/beo-lang.png" alt="Bayesian Eigenobjects" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="http://www.arxiv.org/abs/1905.13153" style="font-weight: bold;">Grounding Language Attributes to Objects using Bayesian Eigenobjects</a><br />
    <strong>Vanya Cohen*</strong>, Benjamin Burchfiel*, Thao Nguyen*, Nakul Gopalan, Stefanie Tellex, George Konidaris.<br />
    <em>IROS 2019</em>, November 2019.<br />
    <a href="http://www.arxiv.org/abs/1905.13153">[paper]</a>
    <a href="https://github.com/vanyacohen/beo-language-grounding">[code]</a>
    <a href="https://h2r.cs.brown.edu/understanding-adjectives/">[project page]</a><br />
    This work presents a method to recognize 3D objects from natural language descriptions and depth images, leveraging unsupervised learning on 3D object meshes to generalize to novel viewpoints.
  </div>
</div>

<div class="paper-container" style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="/assets/img/openwebtext.png" alt="OpenWebText" class="paper-image" style="width: 150px; margin-right: 15px;" />
  <div>
    <a href="https://huggingface.co/datasets/Skylion007/openwebtext" style="font-weight: bold;">OpenWebText: An Open Source Replication of OpenAI's WebText</a><br />
    Aaron Gokaslan*, <strong>Vanya Cohen*</strong>, Ellie Pavlick, Stefanie Tellex.<br />
    <em>NeurIPS NewInML Workshop</em>, May 2019.<br />
    <a href="https://huggingface.co/datasets/Skylion007/openwebtext">[dataset]</a><br />
    OpenWebText replicates OpenAI's WebText dataset and has become a widely used open-source dataset for training language models, with over 4 million downloads.
  </div>
</div>



  

  <ul class="post-list">
    
  </ul>

  


</div>

          </div>
        </main>

        <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy; Vanya Cohen - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a></a>

    </p>

  </div>

</footer>

      </div>
    </div>
  </body>

</html>
