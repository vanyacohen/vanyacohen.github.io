## News

- **[November 2024]**: Excited to share **CaT-Bench**! Our benchmark, [**CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans**](http://www.arxiv.org/abs/2406.15823), presented at [EMNLP 2024](https://2024.emnlp.org/), evaluates how language models handle step dependencies in procedure understanding, revealing challenges for state-of-the-art models. [Check out CaT-Bench on HuggingFace](https://huggingface.co/datasets/vanyacohen/CaT-Bench) and explore the [code here](https://github.com/StonyBrookNLP/CaT-Bench).

- **[August 2024]**: We've presented [**A Survey of Robotic Language Grounding**](http://www.arxiv.org/abs/2405.13245) in the [IJCAI Survey Track](https://ijcai24.org/call-for-papers-survey-track/)! This paper explores the trade-offs in robotic language grounding between symbolic and vector-space representations, with insights into interpretability, generalizability, and scalability. Read more on the [blog](https://h2r.cs.brown.edu/a-survey-of-robotic-language-grounding-tradeoffs-between-symbols-and-embeddings/).

- **[May 2024]**: Announcing **CAPE**! In our ICRA 2024 presentation, [**CAPE: Corrective Actions from Precondition Errors using Large Language Models**](http://www.arxiv.org/abs/2211.09935), we introduced a method that empowers robots to autonomously make corrective actions by re-prompting large language models. Our implementation on the Spot robot demonstrates significant advancements in LLM-assisted robotic planning. Discover more on the [CAPE project page](https://shreyas-s-raman.github.io/CAPE/) and check out our [code base](https://shreyas-s-raman.github.io/CAPE/).